{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90917b5d-8bcb-435d-8362-4399beb0799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Télécharger le dataset depuis Hugging Face\n",
    "dataset = load_dataset(\"PedroSampaio/fruits-360\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfbf1815-4317-4fc1-879c-f2ed2edfbfa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 67690\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 22688\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75ee49cf-b114-4999-a675-cd1f4e15851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamètres optimisés pour économiser les ressources\n",
    "batch_size = 8  # Réduction de la charge mémoire\n",
    "num_epochs = 5  # Moins d'itérations\n",
    "learning_rate = 0.0005  # Plus petit pour un fine-tuning stable\n",
    "image_size = 128  # Réduction de la taille des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5d817be-f32f-40eb-898d-8873acb34d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Définir les transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),  \n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25084f4-0610-444c-b108-feb352a77a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer les transformations aux images\n",
    "def transform_dataset(split):\n",
    "    return [(transform(img[\"image\"]), img[\"label\"]) for img in dataset[split]]\n",
    "\n",
    "train_data = transform_dataset(\"train\")\n",
    "test_data = transform_dataset(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ff4e52-dd03-44cd-bbb1-1f845218e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec0375f-0592-4e80-8a21-f539633b3870",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b56185-46e0-426d-b454-1f0f2c1969ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#Création des DataLoaders\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# Vérification\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f\"Shape des train_images: {images.shape}\")\n",
    "print(f\"train_labels: {labels[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b674890-1d47-4943-b28f-6eceda6b7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# Charger le modèle pré-entraîné ResNet50\n",
    "#model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "# Chargement du modèle ResNet50 pré-entraîné\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# ❄️ Geler toutes les couches sauf la dernière (économie de ressources)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Adapter la dernière couche pour Fruits-360 (nombre de classes à définir)\n",
    "num_classes = 131 \n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4beeb6-6668-4292-a515-9dfc784f633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "# Définir la fonction de perte et l'optimiseur\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f85544e-5a54-482d-aa66-e7e31133ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement avec consommation minimale\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Entraînement en half-precision si GPU\n",
    "        with torch.cuda.amp.autocast() if scaler else torch.no_grad():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        if scaler:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febeca74-d6a6-4aa6-8087-655db10d1f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation du modèle\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Sauvegarde du modèle optimisé\n",
    "torch.save(model.state_dict(), \"resnet50_light.pth\")\n",
    "print(\"Modèle sauvegardé!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b476fed9-8fad-41e1-a138-25bc14e7e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Évaluer le modèle sur l'ensemble de test\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f\"\\nTest Accuracy: {test_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c87e1f-c242-4ec3-93fd-67f7a8ecf6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faire des prédictions\n",
    "y_pred_probs = model.predict(test_images)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df9b666-abb2-4b41-9cc8-02b682930caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# Matrice de confusion\n",
    "conf_matrix = confusion_matrix(test_labels, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815134ec-542b-44c8-93c6-33c41bb90e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Affichage de la matrice de confusion\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=range(131), yticklabels=range(131))\n",
    "plt.xlabel(\"Prédictions\")\n",
    "plt.ylabel(\"Vérités\")\n",
    "plt.title(\"Matrice de Confusion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c9cfe4-8336-4213-861d-e8dea2e4fe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Rapport de classification\n",
    "print(\"Rapport de Classification :\")\n",
    "print(classification_report(test_labels, y_pred, digits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044aacf0-7231-49c6-8ff2-f151ffecd931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Charger une nouvelle image\n",
    "image_path = \"istockphoto-184276818-612x612.jpg\" \n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Appliquer les transformations (resize + normalisation)\n",
    "image = image.resize((100, 100))  \n",
    "image = np.array(image) / 255.0    \n",
    "image = np.expand_dims(image, axis=0)  \n",
    "\n",
    "# Faire la prédiction\n",
    "y_pred_probs = model.predict(image)  \n",
    "y_pred_class = np.argmax(y_pred_probs, axis=1)[0]  \n",
    "\n",
    "# Afficher l’image et la classe prédite\n",
    "plt.imshow(Image.open(image_path))\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Prédiction : Classe {y_pred_class}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4de3d2-f875-4973-a926-b5a1a509fe95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4da951-1604-4ee6-ba3f-83cf43c2b01e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdec68f-0785-4f39-8e2f-b79a38c05d06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
